import sys
from dataclasses import dataclass
from pathlib import Path

# import mlflow
import numpy as np
import torch
import tyro
import yaml
from imgviz import label_colormap
from matplotlib import pyplot as plt
from matplotlib.colorbar import Colorbar
from matplotlib.colors import ListedColormap

sys.path
sys.path.append(".")
sys.path.append("./nerfstudio")

from nerfstudio.engine.trainer import TrainerConfig  # noqa: E402
from nerfstudio.pipelines.base_pipeline import VanillaPipeline  # noqa: E402
from nerfstudio.utils.rich_utils import CONSOLE  # noqa: E402


@dataclass
class AccessCLIArgs:
    """Stores input arguments used for accessing a model."""

    model_uri: str
    """Path to model."""
    dataset_path: Path = None
    """Path to a dataset containing a transforms.json file generated by COLMAP.
    Used to query the dataset first pose to generate a spiral trajectory"""


def get_trainer(model_path: Path) -> TrainerConfig:
    """Get the trainer config associated to the model in `model_path`.

    :return: the trainer config that correspond to the model at `model_path`
    """
    render_config_paths = list(model_path.rglob("config.yml"))

    if len(render_config_paths) == 0:
        raise RuntimeError("No model found at path", model_path)

    with open(render_config_paths[0], "r") as stream:
        config = yaml.load(stream, Loader=yaml.Loader)
    assert isinstance(config, TrainerConfig)

    return config


def load_model(
    model_path: Path,
    data_path: Path,
) -> tuple[VanillaPipeline, TrainerConfig]:
    config = get_trainer(model_path)

    # Get model state
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    checkpoint_path = list(model_path.rglob("*.ckpt"))[-1]
    loaded_state = torch.load(checkpoint_path, map_location=device)

    config.pipeline.datamanager.data = data_path

    # create pipeline from the config file content
    pipeline = config.pipeline.setup(device=device, test_mode="inference")
    pipeline.eval()
    pipeline.load_pipeline(loaded_state["pipeline"], loaded_state["step"])

    return pipeline, config


def set_colorbar(colorbar: Colorbar) -> None:
    colorbar.ax.get_yaxis().set_ticks([])
    for j, lab in enumerate(["background","wall","window","door","roof","others"]):
        colorbar.ax.text(
            1.3,
            (2 * j + 1) / 2.70,
            lab,
            ha="center",
            va="center",
            rotation=270,
        )


def plot_colormap(
    metric: torch.Tensor,
    x_mesh: np.ndarray,
    y_mesh: np.ndarray,
    nbr_points: int,
    cMap: ListedColormap,
):
    fig, ax = plt.subplots()
    metric = metric.reshape((nbr_points, nbr_points))
    x_mesh = x_mesh.reshape((nbr_points, nbr_points))
    y_mesh = y_mesh.reshape((nbr_points, nbr_points))
    plot_colormap = ax.pcolormesh(
        x_mesh,
        y_mesh,
        metric.cpu(),
        cmap=cMap,
    )
    return fig, ax, plot_colormap


def main() -> None:
    tyro.extras.set_accent_color("bright_yellow")
    param = tyro.cli(AccessCLIArgs)

    pipeline, config = load_model(
        Path(param.model_uri),
        param.dataset_path,
    )
    model = pipeline.model

    nbr_points = 1000
    # nbr_points = 1024

    # x_list = np.linspace(-4.1, -3, nbr_points)
    # y_list = np.linspace(-2.5, 4, nbr_points)
    # x_list = np.linspace(-5, 5, nbr_points)
    # y_list = np.linspace(-5, 5, nbr_points)
    # x_list = np.linspace(-1, 6, nbr_points)
    # y_list = np.linspace(-1, 5, nbr_points)
    x_list = np.linspace(-12.5, 12.5, nbr_points)
    y_list = np.linspace(-12.5, 12.5, nbr_points)

    x_mesh, y_mesh = np.meshgrid(x_list, y_list)
    x_mesh = x_mesh.reshape((nbr_points**2, 1))
    y_mesh = y_mesh.reshape((nbr_points**2, 1))

    z_list = np.linspace(0, 15, 15)
    # z_list = np.linspace(0, 7, 30)

    for z in z_list:
        # Get a meshgrid in x-y plain
        positions = np.concatenate(
            [x_mesh, y_mesh, z * np.ones((nbr_points**2, 1))], axis=1
        )
        positions = torch.Tensor(positions)

        # Infer density
        model.field.eval()

        positions = positions.to(torch.device("cuda:0"))

        hidden_output = model.field.forward_geonetwork(positions)

        sdf, geo_feature = torch.split(
            hidden_output, [1, model.field.config.geo_feat_dim], dim=-1
        )

        sdf = sdf.detach().cpu().numpy()
        surface = positions[np.where(np.isclose(sdf, 0, atol=0.01))[0], 0:2].cpu()

        semantic_input = geo_feature.view(-1, model.field.config.geo_feat_dim)

        semantic = model.field.mlp_semantic(semantic_input)
        semantic = model.field.field_head_semantic(semantic)

        semantic_labels = torch.argmax(
            torch.nn.functional.softmax(semantic, dim=-1), dim=-1
        )
        # indexes = np.where(np.equal(np.isclose(sdf, 0, atol=0.002), False))[0]
        # semantic_labels[indexes] = 1
        semantic_labels = (
            semantic_labels.reshape((nbr_points, nbr_points)).detach().cpu().numpy()
        )
        CONSOLE.print("nbr labels: ", np.unique(semantic_labels))

        # # Detect walls and windows in the x-y plain
        # for side in range(4):
        #     side_labels = {0: 0, 3: 0}
        #     for i in range(nbr_points):
        #         for j in range(nbr_points):
        #             if side == 0:
        #                 label = semantic_labels[i, j]
        #             elif side == 1:
        #                 label = semantic_labels[j, i]
        #             elif side == 2:
        #                 label = semantic_labels[i, nbr_points - j - 1]
        #             elif side == 3:
        #                 label = semantic_labels[nbr_points - j - 1, i]

        #             if label == 1:
        #                 continue
        #             elif label == 0 or label == 3:
        #                 building_labels[label] += 1
        #                 side_labels[label] += 1
        #             break

        #     if side_labels[3] != 0:
        #         CONSOLE.print(side_labels)
        #         CONSOLE.print(
        #             "WWR = ",
        #             side_labels[3] / (side_labels[0] + side_labels[3]),
        #         )

        # # Detect roof
        # x_mesh, z_mesh = np.meshgrid(x_list, z_list)
        # x_mesh = x_mesh.reshape((nbr_points**2, 1))
        # z_mesh = z_mesh.reshape((nbr_points**2, 1))

        # nbr_plot_inf = 0
        # nbr_plot_sup = 0

        # for y in y_list:
        #     # Get a meshgrid in x-z plain
        #     positions = np.concatenate(
        #         [x_mesh, y * np.ones((nbr_points**2, 1)), z_mesh], axis=1
        #     )
        #     positions = torch.Tensor(positions)

        #     # Infer density
        #     model.field.eval()
        #     model_output = model.field.mlp_base(positions).reshape((1, nbr_points**2, 16))

        #     density_before_activation, density_embedding = torch.split(
        #         model_output, [1, model.field.geo_feat_dim], dim=-1
        #     )
        #     density = trunc_exp(density_before_activation.to(positions)).detach()

        #     # Infer the semantic label
        #     semantics_input = density_embedding.view(-1, model.field.geo_feat_dim)
        #     semantic_field_output = model.field.mlp_semantics(semantics_input).reshape(
        #         (1, nbr_points**2, 64)
        #     )
        #     semantic_field_output = semantic_field_output.type(torch.float32)
        #     semantic = model.field.field_head_semantics(semantic_field_output)

        #     semantic_labels = torch.argmax(
        #         torch.nn.functional.softmax(semantic, dim=-1), dim=-1
        #     )

        #     # Correct the segmentation according to the density
        #     density = density.reshape((1, nbr_points**2))
        #     semantic_labels[density < 50] = 1
        #     semantic_labels = (
        #         semantic_labels.reshape((nbr_points, nbr_points)).cpu().numpy()
        #     )

        #     # Find start of the wall
        #     roof_start = 0
        #     for i in range(nbr_points):
        #         line_labels = {0: 0, 2: 0, 3: 0}
        #         got_roof: bool = False
        #         for k in range(nbr_points):
        #             label = semantic_labels[nbr_points - k - 1, i]
        #             if label == 1:
        #                 continue
        #             line_labels[label] += 1

        #             if got_roof is False and line_labels[2] >= 5:
        #                 got_roof = True
        #                 line_labels = {0: 0, 2: 0, 3: 0}

        #             if got_roof and line_labels[0] >= 20:
        #                 roof_start = i
        #                 break
        #         if roof_start != 0:
        #             break

        #     # Find end of the wall
        #     roof_end = 0
        #     for i in range(nbr_points):
        #         line_labels = {0: 0, 2: 0, 3: 0}
        #         got_roof: bool = False
        #         for k in range(nbr_points):
        #             label = semantic_labels[nbr_points - k - 1, nbr_points - i - 1]
        #             if label == 1:
        #                 continue
        #             line_labels[label] += 1

        #             if got_roof is False and line_labels[2] >= 5:
        #                 got_roof = True
        #                 line_labels = {0: 0, 2: 0, 3: 0}

        #             if got_roof and line_labels[0] >= 20:
        #                 roof_end = nbr_points - i
        #                 break
        #         if roof_end != 0:
        #             break

        #     if roof_start != 0 and roof_end != 0:
        #         building_labels[0] += roof_end - roof_start
        #         CONSOLE.print("roof : ", roof_start, roof_end)

        #         if (nbr_plot_inf < 5 and roof_start < 100) or (
        #             nbr_plot_sup < 5 and roof_start > 300
        #         ):
        #             if roof_start < 100:
        #                 nbr_plot_inf += 1
        #             if roof_start > 300:
        #                 nbr_plot_sup += 1

        #             CONSOLE.print("line_labels : ", line_labels)

        #             CONSOLE.print("Data plot : ", y, roof_start, roof_end)

        #             colors = ["indigo", "darkviolet", "mediumvioletred", "pink"]
        #             cMap = ListedColormap(colors)

        #             product_fig, product_ax, plot_product = plot_colormap(
        #                 torch.Tensor(semantic_labels),
        #                 x_mesh.reshape((nbr_points, nbr_points)),
        #                 z_mesh.reshape((nbr_points, nbr_points)),
        #                 nbr_points,
        #                 cMap,
        #             )
        #             plot_product.set_clim(0, 3)
        #             colorbar_product = product_fig.colorbar(plot_product)
        #             set_colorbar(colorbar_product)

        #             mlflow.log_figure(product_fig, "product_z_" + str(y) + ".png")

        # CONSOLE.print(building_labels)
        # CONSOLE.print("WWR = ", building_labels[3] / building_labels[0])
        # CONSOLE.print(
        #     "WWR = ", building_labels[3] / (building_labels[0] + building_labels[3])
        # )

        # colors = ["indigo", "darkviolet", "mediumvioletred", "pink"]
        # cMap = ListedColormap(colors)
        # colors = np.array(
        #     [
        #         [224, 224, 192],
        #         [128, 0, 0],
        #         [64, 128, 0],
        #         [0, 128, 128],
        #         [0, 128, 0],
        #         [0, 0, 0],
        #         [128, 192, 128],
        #         [64, 0, 128],
        #         [0, 0, 128],
        #         [192, 0, 192],
        #         [160, 128, 128],
        #         [224, 64, 192],
        #         [128, 64, 0],
        #         [128, 0, 128],
        #         [224, 192, 0],
        #         [64, 128, 128],
        #         [128, 192, 0],
        #         [32, 96, 192],
        #         [96, 32, 192],
        #         [96, 128, 64],
        #         [128, 224, 128],
        #         [0, 160, 192],
        #         [192, 0, 128],
        #         [0, 64, 128],
        #         [64, 64, 0],
        #         [160, 96, 0],
        #         [128, 128, 0],
        #         [64, 192, 128],
        #         [192, 0, 0],
        #         [0, 128, 192],
        #         [0, 32, 128],
        #         [96, 32, 128],
        #         [64, 64, 192],
        #         [0, 192, 0],
        #         [192, 192, 192],
        #         [64, 32, 128],
        #         [96, 128, 192],
        #         [192, 128, 192],
        #         [160, 160, 0],
        #         [32, 64, 0],
        #         [224, 160, 128],
        #         [96, 192, 0],
        #         [128, 64, 128],
        #         [96, 32, 64],
        #     ]
        # )
        # colors = label_colormap()
        colors = np.array(
            [[0.0, 0.0, 0.0],
             [0.49019608, 0.68627451, 0.58823529],
             [0.58823529, 0.88235294, 0.19607843],
             [0, 0.78431373, 0.88235294],
             [0.88235294, 0.78431373, 0.49019608],
             [0.58823529, 0.19607843, 0.09803922]])
        colors = (colors*255).astype(np.uint8)
        cMap = ListedColormap(colors / 255)

        fig, ax, plot_segmentation = plot_colormap(
            torch.Tensor(semantic_labels),
            x_mesh,
            y_mesh,
            nbr_points,
            cMap,
        )
        plot_segmentation.set_clim(0, 3)
        plt.savefig("results/z" + str(z) + ".png")
        # colorbar_segmentation = fig.colorbar(plot_segmentation)
        # set_colorbar(colorbar_segmentation)
        # ax.scatter(surface[:, 0], surface[:, 1], c="red", s=0.01)

        sdf_fig, sdf_ax, sdf_density = plot_colormap(
            torch.Tensor(sdf),
            x_mesh,
            y_mesh,
            nbr_points,
            cMap=None,
        )
        sdf_fig.colorbar(sdf_density)
        sdf_ax.scatter(surface[:, 0], surface[:, 1], c="red", s=0.01)
        plt.savefig("results/density_z" + str(z) + ".png")

        density = sdf.reshape((1, nbr_points**2))
        semantic_labels = semantic_labels.reshape((1, nbr_points**2))
        indexes = np.where(np.equal(np.isclose(density, 0, atol=0.02), False))
        semantic_labels[indexes] = 1
        semantic_labels = torch.Tensor(semantic_labels)
        product_fig, ax, plot_product = plot_colormap(
            semantic_labels,
            x_mesh,
            y_mesh,
            nbr_points,
            cMap=cMap,
        )
        plot_product.set_clim(0, 3)
        # colorbar_product = fig.colorbar(plot_product)
        # set_colorbar(colorbar_product)

        plt.savefig("results/product_z_" + str(z) + ".png")
        # mlflow.log_figure(fig, "z_" + str(z) + ".png")
        # mlflow.log_figure(sdf_fig, "density_z_" + str(z) + ".png")
        # mlflow.log_figure(product_fig, "product_z_" + str(z) + ".png")


if __name__ == "__main__":
    main()
